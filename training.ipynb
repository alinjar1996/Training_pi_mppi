{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0abe92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alinjar/Training_pi_mppi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein_torch import bernstein_coeff_ordern_new\n",
    "import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "from tqdm import trange,tqdm\n",
    "\n",
    "from mlp_manipulator import MLP, MLPProjectionFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "109222da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating P matrix\n",
    "t_fin = 20.0\n",
    "num = 100\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_ordern_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "\n",
    "\n",
    "# P_diag = torch.block_diag(P, P)\n",
    "# Pdot_diag = torch.block_diag(Pdot, Pdot)\n",
    "\n",
    "# Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "nvar_single = P.size(dim = 1) \n",
    "num_dof = 6\n",
    "nvar = nvar_single*num_dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df63ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "xi_filtered (974000, 66)\n",
      "xi_samples (974000, 66)\n",
      "state_terms (974000, 30)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "data = np.load(\"sample_dataset_final.npz\")\n",
    "\n",
    "xi_filtered = data['xi_filtered']\n",
    "xi_samples = data['xi_samples']\n",
    "state_terms = data['state_terms']\n",
    "\n",
    "# Taking the last CEM iteration for samples\n",
    "xi_samples = xi_samples[:, -1]\n",
    "xi_filtered = xi_filtered[:, -1]\n",
    "\n",
    "\n",
    "xi_filtered = xi_filtered.reshape(-1, xi_filtered.shape[2]) \n",
    "xi_samples = xi_samples.reshape(-1, xi_samples.shape[2])\n",
    "state_terms = state_terms.reshape(-1, state_terms.shape[2])\n",
    "\n",
    "datasize = state_terms.shape[0]\n",
    "\n",
    "print(\"xi_filtered\", xi_filtered.shape)\n",
    "print(\"xi_samples\", xi_samples.shape)\n",
    "print(\"state_terms\", state_terms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4463bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp (974000, 96)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "init_state =state_terms\n",
    "\n",
    "c_samples_input = xi_samples\n",
    "\n",
    "\n",
    "inp = np.hstack((init_state, c_samples_input))\n",
    "\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n",
    "\n",
    "print(\"inp\", inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23c6c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajDataset(Dataset):\n",
    "\t\"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "\tdef __init__(self, inp, init_state, c_samples_input):\n",
    "\t\t\n",
    "\t\t# input\n",
    "\t\tself.inp = inp\n",
    "\t\t# State Data\n",
    "\t\tself.init_state = init_state\n",
    "\t\t\n",
    "\t\tself.c_samples_input = c_samples_input\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inp)    \n",
    "\t\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\t# Inputs\n",
    "\t\tinit_state = self.init_state[idx]\n",
    "\t\t\n",
    "\t\tc_samples_input = self.c_samples_input[idx]\n",
    "  \n",
    "\t\tinp = self.inp[idx]\n",
    "\t\t\n",
    "\t\t\t\t \n",
    "\t\treturn torch.tensor(inp).float(), torch.tensor(init_state).float(), torch.tensor(c_samples_input).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65461760",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000 \n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(inp, init_state, c_samples_input)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4edd0db1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_batch \u001b[38;5;241m=\u001b[39m train_loader\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m----> 3\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m Pdot \u001b[38;5;241m=\u001b[39m Pdot\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m Pddot \u001b[38;5;241m=\u001b[39m Pddot\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_batch = train_loader.batch_size\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "Pddot = Pddot.to(device)\n",
    "\n",
    "# CVAE input\n",
    "enc_inp_dim = np.shape(inp)[1] \n",
    "mlp_inp_dim = enc_inp_dim\n",
    "hidden_dim = 1024\n",
    "mlp_out_dim = 4*nvar#+3*num_constraint (lambda- 0:3*nvar, c_samples- 3*nvar:4*nvar)\n",
    "#print(mlp_out_dim)\n",
    "\n",
    "\n",
    "mlp =  MLP(mlp_inp_dim, hidden_dim, mlp_out_dim)\n",
    "\n",
    "#print(mlp)\n",
    "print(\"P\", P.size())\n",
    "\n",
    "model = MLPProjectionFilter(P, Pdot, Pddot, mlp, num_batch, inp_mean, inp_std, t_fin).to(device)\n",
    "\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 #int(datasize/num_batch)\n",
    "print(\"epochs:\", epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step, beta = 0, 1.0 # 3.5\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 2e-4, weight_decay=6e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "losses = []\n",
    "last_loss = torch.inf\n",
    "avg_train_loss, avg_primal_loss, avg_fixed_point_loss = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Loop\n",
    "    losses_train, primal_losses, fixed_point_losses = [], [], []\n",
    "    \n",
    "    for (inp, init_state, c_samples_input) in tqdm(train_loader):\n",
    "        \n",
    "        # Input and Output \n",
    "        inp = inp.to(device)\n",
    "        init_state = init_state.to(device)\n",
    "        c_samples_input = c_samples_input.to(device)\n",
    "\n",
    "        # print(\"inp shape:\", inp.shape)\n",
    "        # print(\"init_state shape:\", init_state.shape)\n",
    "        # print(\"c_samples_input shape:\", c_samples_input.shape)\n",
    "\n",
    "        \n",
    "        c_samples, accumulated_res_fixed_point, accumulated_res_primal, accumulated_res_primal_temp, accumulated_res_fixed_point_temp = model(inp, init_state, c_samples_input)\n",
    "        primal_loss, fixed_point_loss, loss = model.mlp_loss(accumulated_res_primal, accumulated_res_fixed_point, c_samples, c_samples_input)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad() #clears the gradients of the model parameters\n",
    "        loss.backward() #computes the gradients of the model parameters\n",
    "        optimizer.step() #updates the model parameters\n",
    "        \n",
    "        losses_train.append(loss.detach().cpu().numpy()) \n",
    "        primal_losses.append(primal_loss.detach().cpu().numpy())\n",
    "        fixed_point_losses.append(fixed_point_loss.detach().cpu().numpy())\n",
    "        \n",
    "\n",
    "    if epoch % 2 == 0:    \n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, primal loss: {np.average(primal_losses):.3f}, fixed_point loss: {np.average(fixed_point_losses):.3f} \")\n",
    "\n",
    "    #step += 0.07 #0.15\n",
    "    # scheduler.step()\n",
    "    \n",
    "    os.makedirs(\"./training_scripts/weights\", exist_ok=True)\n",
    "    if loss <= last_loss:\n",
    "            torch.save(model.state_dict(), f\"./weights/mlp_learned_proj_manipulator.pth\")\n",
    "            last_loss = loss\n",
    "    avg_train_loss.append(np.average(losses_train)), avg_primal_loss.append(np.average(primal_losses)), \\\n",
    "    avg_fixed_point_loss.append(np.average(fixed_point_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_mppi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
